"""
Backend FastAPI pour l'analyse de march√© KPMG
G√®re les recherches Tavily, l'orchestration LLM et la pr√©paration des donn√©es
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Literal, Optional, List
from datetime import datetime
import os
from dotenv import load_dotenv

# Charger les variables d'environnement depuis le fichier .env
load_dotenv()

# Import des services
from services.tavily_service import TavilyService
from services.llm_service import LLMService
from services.data_service import DataService

# Initialisation de l'application
app = FastAPI(
    title="KPMG Market Analysis API",
    description="API pour l'analyse de march√© avec recherche web et g√©n√©ration IA",
    version="1.0.0"
)

# Configuration CORS
frontend_url = os.getenv("FRONTEND_URL", "http://localhost:3000")
app.add_middleware(
    CORSMiddleware,
    allow_origins=[frontend_url, "http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Initialisation des services avec variables d'environnement syst√®me
tavily_api_key = os.getenv("TAVILY_API_KEY")
openai_api_key = os.getenv("OPENAI_API_KEY")

# Avertissement si les cl√©s ne sont pas d√©finies
if not tavily_api_key:
    print("‚ö†Ô∏è TAVILY_API_KEY non d√©finie - Mode mock activ√©")
if not openai_api_key:
    print("‚ö†Ô∏è OPENAI_API_KEY non d√©finie - Mode mock activ√©")

# Initialiser les services (LLM re√ßoit tavily_service pour l'int√©gration)
tavily_service = TavilyService(api_key=tavily_api_key)
data_service = DataService()
llm_service = LLMService(api_key=openai_api_key, tavily_service=tavily_service, data_service=data_service)

# Mod√®les Pydantic
class SearchRequest(BaseModel):
    query: str
    mode: Literal["general", "data"] = "general"
    max_results: int = 10

class AnalysisRequest(BaseModel):
    query: str
    include_web_search: bool = True

class ChatRequest(BaseModel):
    message: str

class SearchResult(BaseModel):
    title: str
    url: str
    snippet: str
    published_at: Optional[datetime] = None
    source_type: Literal["market_report", "news", "gov_data", "other"]
    reliability_score: int

class MarketData(BaseModel):
    labels: List[str]
    data: List[float]
    unit: str
    sources: List[str]

class AnalysisResponse(BaseModel):
    qualitative: dict
    quantitative: dict
    sources: List[SearchResult]
    generated_at: datetime


# Routes de l'API
@app.get("/")
async def root():
    """Route racine pour v√©rifier l'√©tat de l'API"""
    return {
        "status": "online",
        "service": "KPMG Market Analysis API",
        "version": "1.0.0"
    }

@app.get("/health")
async def health_check():
    """V√©rification de l'√©tat de sant√© de l'API"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "services": {
            "tavily": tavily_service.is_configured(),
            "llm": llm_service.is_configured(),
        }
    }

@app.post("/api/search/general")
async def search_general(request: SearchRequest):
    """
    Recherche web en mode g√©n√©ral (contexte, tendances, acteurs)
    """
    try:
        results = await tavily_service.search(
            query=request.query,
            mode="general",
            max_results=request.max_results
        )
        return {"success": True, "results": results}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/search/data")
async def search_data(request: SearchRequest):
    """
    Recherche web en mode data (chiffres, statistiques, donn√©es quantitatives)
    """
    try:
        results = await tavily_service.search(
            query=request.query,
            mode="data",
            max_results=request.max_results
        )
        return {"success": True, "results": results}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/chat")
async def analyze_chat_input(request: ChatRequest):
    """
    Analyse compl√®te : qualitative (LLM) + quantitative (datasets)
    """
    try:
        print(f"üîç Analyse compl√®te pour: {request.message}")
        
        # Lancer les deux analyses en parall√®le
        import asyncio
        
        # Analyse qualitative (LLM + Tavily)
        qualitative_task = llm_service.analyze_user_input(request.message)
        
        # Analyse quantitative (datasets via APIs)
        quantitative_task = data_service.search_all_apis(request.message)
        
        # Attendre les deux r√©sultats
        qualitative_response, datasets_found = await asyncio.gather(
            qualitative_task,
            quantitative_task
        )
        
        print(f"‚úÖ Analyse qualitative: {len(qualitative_response.get('sources', []))} sources")
        print(f"‚úÖ Analyse quantitative: {len(datasets_found)} datasets")
        
        # Retourner les deux analyses
        return {
            "success": True,
            "response": {
                "response": qualitative_response.get("response", ""),
                "sources": qualitative_response.get("sources", []),
                "datasets": datasets_found  # Maintenant on retourne les datasets
            },
            "generated_at": datetime.now().isoformat()
        }
    
    except Exception as e:
        print(f"‚ùå Erreur analyse compl√®te: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/datasets/search")
async def search_datasets(request: ChatRequest):
    """
    Recherche de datasets via les APIs officielles (INSEE, data.gouv.fr, etc.)
    """
    try:
        print(f"üîç Recherche de datasets pour: {request.message}")
        
        # Rechercher via diff√©rentes APIs
        datasets_found = await data_service.search_all_apis(request.message)
        
        print(f"‚úÖ {len(datasets_found)} datasets trouv√©s")
        
        return {
            "success": True,
            "datasets": datasets_found,
            "count": len(datasets_found)
        }
    
    except Exception as e:
        print(f"‚ùå Erreur recherche datasets: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/datasets/download")
async def download_dataset(request: dict):
    """
    T√©l√©charge et parse un dataset sp√©cifique
    """
    try:
        url = request.get("url")
        if not url:
            raise HTTPException(status_code=400, detail="URL manquante")
        
        print(f"üì• T√©l√©chargement: {url}")
        
        # T√©l√©charger et parser
        parsed = await data_service.download_and_parse(url)
        
        if not parsed:
            raise HTTPException(status_code=500, detail="√âchec du parsing")
        
        return {
            "success": True,
            "dataset": {
                "format": parsed["format"],
                "columns": parsed["columns"],
                "preview": parsed["preview"],
                "total_rows": parsed["total_rows"],
                "url": parsed["url"]
            }
        }
    
    except Exception as e:
        print(f"‚ùå Erreur t√©l√©chargement: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/analysis")
async def generate_analysis(request: AnalysisRequest):
    """
    G√©n√®re une analyse de march√© compl√®te avec recherche web et LLM
    """
    try:
        # √âtape 1: Recherche web si demand√©e
        sources = []
        web_context = ""
        
        if request.include_web_search:
            # Recherche g√©n√©rale pour le contexte
            general_results = await tavily_service.search(
                query=request.query,
                mode="general",
                max_results=5
            )
            
            
            
            sources = general_results
            web_context = tavily_service.format_context_for_llm(sources)
        
        # √âtape 2: G√©n√©ration de l'analyse par le LLM
        analysis = await llm_service.generate_analysis(
            query=request.query,
            web_context=web_context,
            sources=sources
        )
        
        
        return {
            "success": True,
            "analysis": {
                "qualitative": analysis.get("qualitative", {}),
                "sources": sources,
                "generated_at": datetime.now().isoformat()
            }
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("BACKEND_PORT", 8000))
    uvicorn.run("main:app", host="0.0.0.0", port=port, reload=True)
